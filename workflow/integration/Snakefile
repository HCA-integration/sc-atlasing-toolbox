from pathlib import Path
import pandas as pd


def get_h5ad(wildcards):
    return config['DATASETS'][wildcards.dataset]['adata_file']


def get_from_config(config):
    datasets = config['DATASETS']
    records = [
        (dataset, datasets[dataset]['integration'], datasets[dataset]['label'], datasets[dataset]['batch'])
        for dataset in datasets.keys()
    ]
    df = pd.DataFrame.from_records(records,columns=['dataset', 'method', 'label', 'batch'])
    df = df.explode('method')
    return df


def get_params(wildcards, column):
    assert column in parameters.columns
    params_sub = parameters.query('dataset == @wildcards.dataset & method == @wildcards.method')
    param = params_sub[column].unique().tolist()
    if len(param) == 1:
        return param[0]
    return param


parameters = pd.read_table(workflow.source_path('params.tsv'))
parameters = get_from_config(config).merge(parameters,on='method')
out_dir = Path(config['output_dir']) / 'integration'

rule all:
    input: '.snakemake/done.integration'


rule run:
    message:
        """
        params: {params}
        input: {input}
        output: {output}
        """
    input:
        h5ad=get_h5ad
    output:
        out_dir / '{dataset}/{method}.h5ad'
    params:
        dataset=lambda wildcards: get_params(wildcards,'dataset'),
        batch=lambda wildcards: get_params(wildcards,'batch'),
        label=lambda wildcards: get_params(wildcards,'label'),
        output_type=lambda wildcards: get_params(wildcards,'output_type'),
        env=lambda wildcards: get_params(wildcards,'env')
    conda:
        lambda wildcards, params: f'envs/{params.env}'
    script:
        'scripts/{wildcards.method}.py'


rule collect:
    input:
        expand(
            rules.run.output,
            zip,
            **parameters[['dataset', 'method']].to_dict('list')
        )
    output: touch('.snakemake/done.integration')
