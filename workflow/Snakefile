from pathlib import Path
import pandas as pd
from snakemake.utils import min_version

from utils import get_wildcards_from_config, _get_or_default_from_config, get_wildcards


min_version("6.0")
container: "docker://condaforge/mambaforge:latest"
configfile: "configs/config.yaml"

params = pd.read_table('configs/modules.tsv',comment='#')
params['submodules'] = params['submodules'].str.split(',')

# Process params per module
for dataset in config['DATASETS'].keys():

    def _get(params, dataset, module):
        submodules = params.query('dataset == @dataset and module == @module')['submodules']
        if len(submodules) == 0 or submodules.isna().all():
            submodules = _get_or_default_from_config(config['DATASETS'],config['defaults'],dataset,module)
        else:
            submodules = submodules.to_list()[0]
        if len(submodules) == 0:
            raise ValueError(
                f'No submodules defined for {dataset}, {module}.'
                ' Check that they are either defined either in the config or modules.tsv'
            )
        return submodules


    config['DATASETS'][dataset]['integration'] = _get(params,dataset,'integration')
    config['DATASETS'][dataset]['metrics'] = _get(params,dataset,'metrics')

config['dataset_meta'] = str(Path(config['dataset_meta']).resolve())

out_dir = Path(config['output_dir'])

# Import modules
module load_data:
    snakefile: "load_data/Snakefile"
    config: config

module exploration:
    snakefile: "exploration/Snakefile"
    config: config

module preprocessing:
    snakefile: "preprocessing/Snakefile"
    config: config

module label_transfer:
    snakefile: "label_transfer/Snakefile"
    config: config

module integration:
    snakefile: "integration/Snakefile"
    config: config

module metrics:
    snakefile: "metrics/Snakefile"
    config: config

use rule * from load_data as load_data_ *

use rule * from exploration as exploration_ *

use rule * from preprocessing as preprocessing_ *

use rule * from label_transfer as label_transfer_ *

use rule * from integration as integration_ *

use rule * from metrics as metrics_ *


rule all:
    input:
        rules.load_data_all.input,
        rules.exploration_all.input,
        # rules.preprocessing_all.input,
        # rules.label_transfer_all.input,
        rules.integration_all.input,
        rules.metrics_all.input
    default_target: True


#benchmark_params = get_wildcards_from_config(
#    config=config,
#    config_keys=['pancreas_ari_nmi', 'pancreas_asw', 'pancreas_lisi'],
#    config_params=['integration', 'metrics'],
#    wildcard_names=['dataset', 'method', 'metric'],
#    explode_by=['method', 'metric']
#)

#use rule merge from metrics as benchmark_pancreas with:
#    input:
#       metrics=expand(rules.run.output,zip,**benchmark_params),
#        benchmark=expand(rules.run.benchmark,zip,**benchmark_params),
#    output:
#        metrics=out_dir / 'benchmark_metrics_pancreas' / 'metrics.tsv',
#        plot=out_dir / 'benchmark_metrics_pancreas' / 'metrics.png',
#        time=out_dir / 'benchmark_metrics_pancreas' / 'time.png',
#    params:
#        wildcards=get_wildcards(benchmark_params,['dataset', 'method', 'metric'])
