from pathlib import Path
import pandas as pd
from snakemake.utils import min_version

from utils import get_wildcards_from_config


min_version("6.0")
container: "docker://condaforge/mambaforge:latest"
configfile: "configs/config.yaml"

params = pd.read_table('configs/modules.tsv',comment='#')
params['submodules'] = params['submodules'].str.split(',')

# Process params per module
for dataset in config['DATASETS'].keys():

    def _get(params, dataset, module):
        submodules = params.query('dataset == @dataset and module == @module')['submodules']
        if len(submodules) == 0 or submodules.isna().all():
            submodules = config['DATASETS'][dataset][module]
        else:
            submodules = submodules.to_list()[0]
        if len(submodules) == 0:
            raise ValueError(
                f'No submodules defined for {dataset}, {module}.'
                ' Check that they are either defined either in the config or modules.tsv'
            )
        return submodules


    config['DATASETS'][dataset]['integration'] = _get(params,dataset,'integration')
    config['DATASETS'][dataset]['metrics'] = _get(params,dataset,'metrics')

config['dataset_meta'] = str(Path(config['dataset_meta']).resolve())

out_dir = Path(config['output_dir'])


# Import modules
module load_data:
    snakefile: "load_data/Snakefile"
    config: config

module preprocessing:
    snakefile: "preprocessing/Snakefile"
    config: config

module label_transfer:
    snakefile: "label_transfer/Snakefile"
    config: config

module integration:
    snakefile: "integration/Snakefile"
    config: config

module metrics:
    snakefile: "metrics/Snakefile"
    config: config

use rule * from load_data as load_data_ *

use rule * from preprocessing as preprocessing_ *

use rule * from label_transfer as label_transfer_ *

use rule * from integration as integration_ *

use rule * from metrics as metrics_ *

metrics_wildcards = get_wildcards_from_config(
    config=config['DATASETS'],
    config_params=['integration', 'metrics', 'label', 'batch'],
    wildcard_names=['dataset', 'method', 'metric', 'label', 'batch'],
    explode_by=['method', 'metric']
)
print(metrics_wildcards)

use rule merge from metrics as metrics_merge with:
    input: expand(rules.run.output,zip,**metrics_wildcards)

print(rules.metrics_all.input)

rule collect:
    input:
        # rules.load_data_all.input,
        # rules.preprocessing_all.input,
        # rules.label_transfer_all.input,
        rules.integration_all.input,
        rules.metrics_all.input
    output:
        touch('.snakemake/done')
    default_target: True


rule download_pancreas:
    input: expand(rules.load_data_download.output,dataset='pancreas')


benchmark_params = get_wildcards_from_config(
    config['DATASETS'],
    config_keys=['pancreas'],
    config_params=['integration', 'metrics'],
    wildcard_names=['dataset', 'method', 'metric'],
    explode_by=['method', 'metric']
)

use rule metrics_benchmark as benchmark_pancreas with:
    input:
        benchmark=expand(rules.run.benchmark,zip,**benchmark_params)
    output:
        benchmark=out_dir / 'metrics' / 'pancreas_benchmark.tsv'
    params:
        wildcards=benchmark_params
