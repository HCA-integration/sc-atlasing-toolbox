from pathlib import Path
import pandas as pd
from snakemake.utils import min_version

from utils import _get_or_default_from_config, set_defaults


min_version("6.0")
container: "docker://condaforge/mambaforge:latest"
configfile: "configs/config.yaml"
configfile: "configs/subset.yaml"

params = pd.read_table('configs/modules.tsv',comment='#')
params['submodules'] = params['submodules'].str.split(',')

# Process params per module
for dataset in config['DATASETS'].keys():

    def _get(params, dataset, module):
        submodules = params.query('dataset == @dataset and module == @module')['submodules']
        if len(submodules) == 0 or submodules.isna().all():
            submodules = _get_or_default_from_config(config['DATASETS'],config['defaults'],dataset,module)
        else:
            submodules = submodules.to_list()[0]
        if len(submodules) == 0:
            raise ValueError(
                f'No submodules defined for {dataset}, {module}.'
                ' Check that they are either defined either in the config or modules.tsv'
            )
        return submodules


    config['DATASETS'][dataset]['integration'] = _get(params,dataset,'integration')
    config['DATASETS'][dataset]['metrics'] = _get(params,dataset,'metrics')

config = set_defaults(config,['integration', 'metrics'])
config['dataset_meta'] = str(Path(config['dataset_meta']).resolve())

out_dir = Path(config['output_dir'])

# Import modules
module common:
    snakefile: "common/Snakefile"
    config: config

module load_data:
    snakefile: "load_data/Snakefile"
    config: config

module exploration:
    snakefile: "exploration/Snakefile"
    config: config

module subset:
    snakefile: "subset/Snakefile"
    config: config

module preprocessing:
    snakefile: "preprocessing/Snakefile"
    config: config

module label_transfer:
    snakefile: "label_transfer/Snakefile"
    config: config

module integration:
    snakefile: "integration/Snakefile"
    config: config

module metrics:
    snakefile: "metrics/Snakefile"
    config: config

use rule * from common as common_ *

use rule * from load_data as load_data_ *

use rule * from exploration as exploration_ *

use rule * from subset as subset_ *

use rule * from preprocessing as preprocessing_ *

use rule * from label_transfer as label_transfer_ *

use rule * from integration as integration_ *

use rule * from metrics as metrics_ *


rule all:
    input:
        rules.load_data_all.input,
        rules.exploration_all.input,
        rules.subset_all.input,
        # rules.preprocessing_all.input,
        # rules.label_transfer_all.input,
        rules.integration_all.input,
        rules.metrics_all.input
    default_target: True


modules = ['load_data', 'exploration', 'subset', 'integration', 'metrics']

rule dependency_graph:
    input:
        expand(
            rules.common_dependency_graph.input,
            images=config['images'],
            target=[f'{_module}_all' for _module in modules] + ['all']
        )