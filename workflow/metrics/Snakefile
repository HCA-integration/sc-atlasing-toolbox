"""
Metrics
"""
from pathlib import Path
import pandas as pd

from utils import get_hyperparams, expand_per, get_params, get_resource, get_wildcards, get_wildcards_from_config, \
    set_defaults


def all_but(_list, is_not):
    return [x for x in _list if x != is_not]


module integration:
    snakefile: "../integration/Snakefile"
    config: config

use rule * from integration as integration_ *


module_name = 'metrics'
config = set_defaults(config,module_name)
out_dir = Path(config['output_dir']) / module_name

wildcards_df = get_wildcards_from_config(
    config=config['DATASETS'],
    config_keys=config['defaults']['datasets'],
    config_params=['integration', 'metrics', 'label', 'batch'],
    wildcard_names=['dataset', 'method', 'metric', 'label', 'batch'],
    explode_by=['method', 'metric'],
)

# # get wildcards from input directory
# datasets, methods = glob_wildcards(in_path)
# integration_wildcards = pd.DataFrame({'dataset': datasets, 'method': methods})
# # get full parameters
# wildcards_df = get_wildcards_from_config(
#     config=config,
#     config_params=['metrics', 'label', 'batch'],
#     wildcard_names=['dataset', 'metric', 'label', 'batch'],
#     explode_by='metric'
# ).merge(
#     integration_wildcards,
#     on='dataset'
# )

parameters = pd.read_table(workflow.source_path('params.tsv'))
parameters = wildcards_df \
    .merge(parameters,on='metric') \
    .merge(get_hyperparams(config,module='integration'),on=['dataset', 'method'],how='left')

wildcard_names = ['dataset', 'method', 'metric', 'batch', 'label', 'hyperparams']


module common:
    snakefile: "../common/Snakefile"
    config: config


use rule * from common as common_ *


rule run:
    message:
       """
       Evaluate {wildcards.metric} on {wildcards.dataset}
       input: {input}
       output: {output}
       wildcards: {wildcards}
       resources: gpu={resources.gpu}
       """
    input:
        h5ad=rules.integration_run.output.h5ad,
        metrics_meta=workflow.source_path('params.tsv')
    output:
        metric=out_dir / 'datasets/{dataset}/{method}/batch={batch},label={label},hyperparams={hyperparams}/{metric}.tsv'
    params:
        env=lambda wildcards: get_params(wildcards,parameters,'env')
    conda:
        lambda wildcards, params: f'envs/{params.env}.yaml'
    resources:
        partition=lambda w: get_resource(config,profile=get_params(w,parameters,'resources'),resource_key='partition'),
        qos=lambda w: get_resource(config,profile=get_params(w,parameters,'resources'),resource_key='qos'),
        gpu=lambda w: get_resource(config,profile=get_params(w,parameters,'resources'),resource_key='gpu'),
        mem_mb=lambda w: get_resource(config,profile=get_params(w,parameters,'resources'),resource_key='mem_mb'),
        disk_mb=100
    benchmark:
        out_dir / 'datasets/{dataset}/{method}/batch={batch},label={label},hyperparams={hyperparams}/{metric}.benchmark.tsv'
    script:
        'scripts/{wildcards.metric}.py'


rule merge:
    message:
        """
        Merge all metrics for all datasets and methods
        datasets: {params.wildcards[dataset]}
        methods: {params.wildcards[method]}
        """
    input:
        metrics=lambda wildcards: expand_per(rules.run.output,parameters,wildcards,wildcard_names),
        benchmark=lambda wildcards: expand_per(rules.run.benchmark,parameters,wildcards,wildcard_names),
    output:
        metrics=out_dir / 'metrics.tsv',
        plot=out_dir / 'metrics.png',
        time=out_dir / 'metrics_time.png',
    params:
        wildcards=get_wildcards(parameters,wildcard_names)
    conda: 'envs/scanpy.yaml'
    resources:
        mem_mb=1000,
        disk_mb=500
    script: 'scripts/merge.py'


use rule merge as merge_per_dataset with:
    message:
        """
        Merge all metrics for {wildcards}
        """
    input:
        metrics=lambda wildcards: expand_per(rules.run.output,parameters,wildcards,all_but(wildcard_names,'dataset')),
        benchmark=lambda wildcards: expand_per(rules.run.benchmark,parameters,wildcards,all_but(wildcard_names,'dataset')),
    output:
        metrics=out_dir / 'per_dataset' / '{dataset}_metrics.tsv',
        plot=out_dir / 'per_dataset' / '{dataset}.png',
        time=out_dir / 'per_dataset' / '{dataset}_time.png',
    params:
        wildcards=lambda wildcards: get_wildcards(parameters,all_but(wildcard_names,'dataset'),wildcards)


use rule merge as merge_per_method with:
    message:
        """
        Merge all metrics for {wildcards}
        """
    input:
        metrics=lambda wildcards: expand_per(rules.run.output,parameters,wildcards,all_but(wildcard_names,'method')),
        benchmark=lambda wildcards: expand_per(rules.run.benchmark,parameters,wildcards,all_but(wildcard_names,'method')),
    output:
        metrics=out_dir / 'per_method' / '{method}.tsv',
        plot=out_dir / 'per_method' / '{method}.png',
        time=out_dir / 'per_method' / '{method}_time.png',
    params:
        wildcards=lambda wildcards: get_wildcards(parameters,all_but(wildcard_names,'method'),wildcards)


rule all:
    input:
        expand(rules.merge_per_dataset.output,zip,**get_wildcards(parameters,['dataset'])),
        expand(rules.merge_per_method.output,zip,**get_wildcards(parameters,['method'])),
        rules.merge.output,
    default_target: True


rule dependency_graph:
    input:
        expand(
            rules.common_dependency_graph.input,
            images=config['images'] + f'/{module_name}',
            target='all'
        )


rule compare_metrics:
    input:
        tsv=rules.merge.output.metrics
    output:
        png=out_dir / 'plots' / 'comparison.png'
    conda:
        'envs/plots.yaml'
    script:
        'scripts/plots/comparison.py'