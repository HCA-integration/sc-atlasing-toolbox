from pathlib import Path
import pandas as pd

from utils import get_wildcards_from_config


out_dir = Path(config['output_dir']) / 'metrics'
# TODO: save input pattern in config
in_path = Path(config['output_dir']) / 'integration' / '{dataset}' / '{method}.h5ad'

# get wildcards from input directory
datasets, methods = glob_wildcards(in_path)
integration_wildcards = pd.DataFrame({'dataset': datasets, 'method': methods})

# get full parameters
parameters = get_wildcards_from_config(
    config['DATASETS'],
    ['metrics', 'label', 'batch'],
    ['dataset', 'metric', 'label', 'batch'],
    explode_by='metric'
).merge(
    integration_wildcards,
    on='dataset'
)


rule run:
    message:
        """
        Evaluate {wildcards.metric} on {wildcards.dataset}
        input: {input}
        output: {output}
        wildcards: {wildcards}
        """
    input:
        h5ad=in_path,
        metrics_meta=workflow.source_path('params.tsv')
    output:
        metric=out_dir / '{dataset}/{method}/{metric}.tsv'
    conda:
        '../../envs/scib.yaml'
    benchmark:
        out_dir / '{dataset}/{method}/{metric}.benchmark.tsv'
    script:
        'scripts/{wildcards.metric}.py'


rule merge:
    input:
        metrics=expand(rules.run.output,zip,**parameters[['dataset', 'method', 'metric']].to_dict('list')),
    output:
        metrics=out_dir / 'metrics.tsv',
    run:
        metrics_df = pd.concat([pd.read_table(file) for file in input.metrics])
        metrics_df.to_csv(output.metrics,sep='\t',index=False)


rule benchmark:
    input:
        benchmark=expand(rules.run.benchmark,zip,**parameters[['dataset', 'method', 'metric']].to_dict('list'))
    output:
        benchmark=out_dir / 'metrics.benchmark.tsv'
    params:
        wildcards=parameters[['dataset', 'method', 'metric']]
    run:
        benchmark_df = pd.concat([pd.read_table(file) for file in input.benchmark]).reset_index(drop=True)
        benchmark_df = pd.concat([params.wildcards.reset_index(drop=True), benchmark_df],axis=1)
        print(benchmark_df)
        benchmark_df.to_csv(output.benchmark,sep='\t',index=False)


rule all:
    input:
        rules.merge.output
    default_target: True
